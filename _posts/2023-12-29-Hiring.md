# 昨天忘了一件事：招聘

有朋友在问：**为什么大模型方向国产AI芯片有机会？**

我的观点是：

- 大模型没有那么多“技术负债”与“技术鸿沟”，大家可以说终于在一个起跑线了，起步的机会相当；
- 
- 过去的技术积累肯定有价值，但不像`CV`对**泛化**和**性能**和**不修改代码迁移**既要、又要、还要**成为编译、算子、工具团队的“不可能完成的任务”；
-
- 训练可以做`PR`和中小规模的`微调`，推理落地才是真机会，而推理对于目前绝大多数芯片来说，是计算性能过剩的；
- 
- 所以，我相信有决策快的团队针对大模型的新的芯片设计应该差不多了，就差老板拍板赌一把模型结构三年不会颠覆了；

再问：这种**专用**芯片做出来，`CV`市场怎么办？

我的想法是：

现在大家手里人手起码一颗芯片，干的快的云端芯片手里都有三颗了，这些芯片都回来了，该怎么卖就怎么卖，总不能放仓库供起来吧？

在`CV`卖不掉的芯片，为啥到了大模型就一定有竞争力了（终于能卖掉了，不代表有竞争力，那是时间窗口的问题）？

换句话：**大号**眼看练废了，弄个**小号**打打，说不定柳暗花明呢？


昨天忘了答应朋友的事情：帮着发个招聘的信息，看看年底有没有有缘人。

具体哪家我就不在这里写了，不太好，感觉被充值了🤐

## 编译

编译前端，后端都需要。

后端相对更缺，主要还是希望看经验好一点的，所以就“更缺”，没啥毛病。

要求：
- 目前在折腾`MLIR`最好
- 自己看过`MLIR`，但是现在公司用`TVM`也能聊聊看

## 推理工具

这个没啥好解释的，就是做类似：

- `TensorRT`
- `vLLM`
- `TGI`

这样事情，大家都在做，技术栈需求无须多言。

## 其他

其他芯片软件栈相关的也需要，没上面两个那么那么缺人干活😁。

所以，`运行时`、`SDK`、`PyTorch后端集成`、`分布式`这些方向的兄弟们有想法，应该也是可以聊聊的。

好了，补上了，今天就到此结束了。

今年，也基本上到此为止了，新年快乐🎉。

欢迎加我的微信“**doubtthings**”，欢迎交流与探讨。

欢迎关注我的公众号“**书不可尽信**”，原创文章第一时间推送。

<center>
    <img src="https://s2.loli.net/2022/11/27/WAC1ml5X8GTvOuH.jpg" style="width: 100px;">
</center>